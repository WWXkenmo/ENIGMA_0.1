#' @title ENIGMA L2 max norm version
#'
#' @param object ENIGMA object
#' @param alpha
#' ENIGMA is a multi-objective optimization problem involve two object function, the distance function between observed bulk RNA-seq and reconstitute RNA-seq generated by weighted combination of CSE, and the distance function beween average CSE expression and cell type reference matrix. The alpha is used to determine weights of these two objects. If the alpha gets larger, the optimization attach greater importance on the the first object. Default: 0.5
#'
#' @param tao_k
#' The step size of each round of gradient decent. Default: 0.01
#'
#' @param beta
#' The regularization parameter to penalize the weight (deconvoluted expression) matrices from being too large. Default: 8000
#'
#' @param epsilon
#' Determine the stop condition in CSE updating. Default: 0.001
#'
#' @param max.iter
#' The maximum number of iterations. Default: 1000
#'
#' @param verbose
#' Whether return the information after each step of processing. Default: TRUE
#'
#' @param infer
#' Whether return the re-estimated cell type fractions. Default: FALSE
#'
#' @param pos
#' Whether set all entries in CSE is positive. Default: TRUE
#'
#' @param Normalize
#' Whether perform normalization on resulted expression profile. Default: TRUE
#'
#' @param Norm.method
#' Method used to perform normalization. User could choose PC or frac
#' 
#' @param preprocess
#' Method used to perform variance stablization preprocessing. User could choose var or log
#'
#' @export
ENIGMA_L2_max_norm <- function (object, alpha = 0.5, beta = 100, gamma = 1, epsilon = 1e-04, 
    max.iter = 100, verbose = TRUE,Normalize = TRUE, Norm.method = "PC",preprocess = "var") 
{
    if(preprocess == "var") O = sqrt(object@bulk)
	if(preprocess == "log") O = log2(object@bulk+1)
	
    theta = object@result_cell_proportion
    R = sqrt(object@ref)
    X = array(0, dim = c(nrow(O), ncol(O), ncol(theta)), dimnames = list(rownames(O), 
        colnames(O), colnames(theta)))
    for (i in 1:ncol(theta)) {
        X[, , i] <- O
    }
    A <- Y <- X
    A_k_1 <- A_k <- A
    Y_k_1 <- Y_k <- Y
    X_k_1 <- X_k <- X
    a <- as.matrix(rep(1/nrow(theta), nrow(theta)))
    F = array(0, dim = c(ncol(O), ncol(O), ncol(theta)), dimnames = list(colnames(O), 
        colnames(O), colnames(theta)))
    for (i in 1:ncol(theta)) {
        F[, , i] <- getF(theta[, i], alpha, gamma, a)
    }
    theta_hat <- colMeans(theta)
    k <- 0
    delta <- 10000
    repeat {
        if (abs(delta) < epsilon || k > max.iter) {
            break
        }
        else {
            X_k <- X_k_1
            Y_k <- Y_k_1
            A_k <- A_k_1
            ratio <- NULL
            for (j in 1:ncol(theta)) {
                T_k_j <- getT(j, X_k, theta, O, alpha)
                X_k_1[, , j] <- ((1 - alpha) * as.matrix(R[, 
                  j]) %*% t(a) - A_k[, , j] + gamma * Y_k[, , 
                  j] - T_k_j) %*% F[, , j]
                Y_k_1[, , j] <- SVT(((A_k[, , j]/gamma) + X_k_1[, 
                  , j]), (beta * theta_hat[j])/gamma)
                A_k_1[, , j] <- A_k[, , j] + gamma * (X_k_1[, 
                  , j] - Y_k_1[, , j])
                ratio <- c(ratio, sum((X_k_1[, , j] - X_k[, , 
                  j])^2)/sum(X_k[, , j]^2))
            }
            if (verbose) 
                writeLines(sprintf("   Ratio ranges from: %f - %f", 
                  min(ratio), max(ratio)))
            r <- loss(O, X_k, theta, alpha, beta, R)
            if (verbose) 
                writeLines(sprintf("   Loss: part1=%f , part2=%f , part3=%f", 
                  r$part1, r$part2, r$part3))
            delta <- max(ratio)
            k <- k + 1
        }
    }
	
    writeLines(paste("Converge in ", k, " steps", sep = ""))
	
	if(Normalize){
	cat("Perform Normalization...")
	if(Norm.method == "PC"){
	X_k_norm <- X_k
	for(k in 1:dims(X_k)[3]){
	   if(preprocess == "var") exp <- X_k[,,k]^2
	   if(preprocess == "log") exp <- 2^X_k[,,k] - 1
	   
	   exp.scale <- t(apply(exp,1,scale))
	   PC <- svd(exp.scale)$v[,1]
	   exp.norm <- NULL
	   for(i in 1:nrow(exp)){
	      lm.model <- lm(exp[i,]~PC)
		  exp.norm <- rbind(exp.norm, (exp[i,] - lm.model$coefficients[2] * PC))
	   }
	   X_k_norm[,,k] <- exp.norm
	}
	}
	
	if(Norm.method == "frac"){
	X_k_norm <- X_k
	for(k in 1:dims(X_k)[3]){
	   if(preprocess == "var") exp <- X_k[,,k]^2
	   if(preprocess == "log") exp <- 2^X_k[,,k] - 1
	   
	   exp.norm <- NULL
	   for(i in 1:nrow(exp)){
	      lm.model <- lm(exp[i,]~theta[,k])
		  exp.norm <- rbind(exp.norm, (exp[i,] - lm.model$coefficients[2] * theta[,k]))
	   }
	   X_k_norm[,,k] <- exp.norm
	}
	}
	object@result_CSE_normalized <- res2sce(X_k_norm)
	}
    if(preprocess == "var") object@result_CSE = res2sce(X_k^2)
	if(preprocess == "log") object@result_CSE = res2sce(2^X_k - 1)
    return(object)
}


sub_loss <- function(X, P_old, theta, alpha,beta,R){
    # X: Bulk gene expression dataset (g*n)
    # P_old: cell type specific gene expression profile (g*n*p)
    # theta: cell type ratio for each samples (n*p)
    # alpha: constraint parameters of the similarity between each estimated cell type specific expression and reference profile, constant
    # beta:  constraint parameters of the smoothness of gene expression, constant
    # R: reference profile (g*p)

    part1 <- 0
    for(i in 1:ncol(theta)){
        part1 <- part1+P_old[,,i]%*%diag(theta[,i])
    }
    part1 <- part1
    # part1 <- norm((X-part1),"F")^2
    part1 <- sum( (X-part1)^2 )

    part2 <- 0
    for(i in 1:ncol(R)){
        ref <- matrix(rep(R[,i],ncol(X)),nrow=length(R[,i]))
        # part2 <- part2 + alpha*norm((P_old[,,i]-ref),"F")^2
        part2 <- part2 + alpha*sum( (P_old[,,i]-ref)^2 )
    }

    part3 <- 0
    for(i in 1:ncol(R)){
        # norm <- apply(P_old[,,i],2,norm,"2")
        part3 <- part3 + max( colSums(P_old[,,i]^2) )
    }

    res <- list()
    val <- part1+part2+beta*part3
    res$val <- val
    res$part1 <- part1
    res$part2 <- part2/alpha
    res$part3 <- part3
    res
}

squash <- function(V, beta){
    ## squash: calculate the optimal solution of the formula: X=argmin{ (||X-V||_F)^2 + beta*||X||_2_max }
    n <- NULL
    for(i in 1:nrow(V)){
        n <- c(n, sqrt( sum(V[i,]^2) ) )
    }
    pi <- order(n,decreasing=TRUE)
    s <- NULL
    for(i in 1:length(pi)){
        s <- c(s, sum(n[pi[1:i]]))
    }
    q <- max(which(n[pi]>=s/(c(1:length(s))+beta)))
    tao <- s[q]/(q+beta)

    for(i in 1:q){
        V[pi[i],] <- tao*V[pi[i],]/sqrt( sum(V[pi[i],]^2) )
    }

    V
}

proximalpoint <- function(P, tao_k,dP,beta){
    # X: Bulk gene expression dataset (g*n)
    # P_old: cell type specific gene expression profile (g*n*p)
    # theta: cell type ratio for each samples (n*p)
    # alpha: constraint parameters of the similarity between each estimated cell type specific expression and reference profile, constant
    # beta:  constraint parameters of the smoothness of gene expression, constant
    # R: reference profile (g*p)
    # P: the ith cell type specific gene expression profile needs to be undated
    # tao_k: gradient size
    # dP: gradient of matrix P
    # scale_alpha: the parameters for inequality decision
    # beta:  constraint parameters of the smoothness of gene expression, constant
    # cell_type_index: optimize which type of cells
    # gamma: the parameters for inequality decision

    P_hat <- t(squash(t(P-tao_k*dP),tao_k*beta))
    ##update P matrix
    return(P_hat)
}



derive_P2 <- function(X, theta, P_old,R,alpha){
    ## P_old: a tensor variable with three dimensions
    ## theta: the cell type proportions variable
    ## cell_type_index: optimize which type of cells
    ## R: reference matrix
    dP1 <- dP2 <- array(0,
                        dim = c( nrow(X),
                                 ncol(X),
                                 ncol(theta)),
                        dimnames = list( rownames(X),
                                         colnames(X),
                                         colnames(theta))
    )
    for(cell_type_index in 1:ncol(theta)){
        R.m <- as.matrix(R[,cell_type_index])

        cell_type_seq <- c(1:ncol(theta))
        cell_type_seq <- cell_type_seq[cell_type_seq!=cell_type_index]

        X_summary = Reduce("+",
                           lapply(cell_type_seq, function(i) P_old[,,i]%*%diag(theta[,i]) )
        )
        X_summary <- X-X_summary

        dP1[,,cell_type_index] <- 2*(P_old[,,cell_type_index]%*%diag(theta[,cell_type_index]) - X_summary)%*%diag(theta[,cell_type_index])
        dP2[,,cell_type_index] <- 2*(as.matrix(rowMeans(P_old[,,cell_type_index]))-R.m)%*%t(as.matrix(rep((1/ncol(dP2[,,cell_type_index])),ncol(dP2[,,cell_type_index]))))
    }
    dP1 = dP1 / sqrt( sum( dP1^2 ) ) * 1e5
    dP2 = dP2 / sqrt( sum( dP2^2 ) ) * 1e5

    #calculate w1
    #if( crossprod(as.matrix(dP1), as.matrix(dP2)) >= crossprod(as.matrix(dP1)) ) {w1 = 1}
    #else if( crossprod(as.matrix(dP1), as.matrix(dP2)) >= crossprod(as.matrix(dP2)) ) {w1 = 0}
    #else {
    #    w1 = crossprod(as.matrix(dP2-dP1), as.matrix(dP2))/sum((dP1-dP2)^2)
    #}
    w1 <- alpha
    w2 <- 1-w1

    dP <- dP1*as.numeric(w1) + dP2*as.numeric(w2)
    return(dP)
}